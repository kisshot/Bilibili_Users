# Bilibili_Users
使用Redis,Scrapy,MongoDB实现分布式爬虫，抓取Bilibil用户信息
这个项目是我初学爬虫的应用，接下来的几个月我将会逐步完善代码。
## 项目分为4个阶段：
**阶段1：简单的用户信息抓取，不涉及代理池等反爬虫措施，仅用于熟悉流程 \
阶段2：使用scrapy框架完成抓取，连接代理池，cookie池，将结果存储于MongoDB数据库中 \
阶段3：在阶段2的基础上实现分布式爬虫，使用redis实现 \
阶段4：借助爬取到的数据进行用户资料的分析** 
## 文件介绍
* **第一阶段暂存**： \
抓取用户信息，config文件为MongoDB配置文件，user_agents为User-Agent选择文件 \
这个用户信息———>这个用户关注者有谁———>这个用户的关注者信息———>关注者的关注者有谁———>关注者的关注者的个人信息 \
循环抓取，由用户得到关注者再得到关注者的关注者，循环往复 \
连接代理池@jhao104/proxy_pool，信息存储到MongoDB中 \
